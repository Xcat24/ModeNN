# A Broad Learning Framework
A transformative machine learning concept and realization of thoroughly parallel neural computing for next-generation AI.

## Abstract
People have struggled to invent shallow broad structured machine learning approaches to achieve high parallelism, faster learning, higher reliability and generality. To resolve these issues, we propose a broad learning concept, achieving equivalent capacity and efficiency to deep learning, with better parallelizability and implementation effectiveness. We introduce multi-order Descartes expansion (MODE) transformations to non-linearly map the original data into a high dimensional MODE space for better feature representation. Here, a MODE neural network (MODENN) is constructed for a single layer that is both theoretically and experimentally demonstrated as a universal logic calculator, continuous function approximator, and pattern classifier. Our method can perform various complex functions that deep learning and deep neural networks can implement, while retaining greater potentiality in model complexity, performance, robustness, and interpretability.

Full paper: https://ieeexplore.ieee.org/abstract/document/9606548/

## Quickstart
```bash
bash ./example/ModeNN_mnist.sh
```
## Reference
Please consider citing this work if it helps your research.
```
@article{li2021modenn,
  title={MODENN: A Shallow Broad Neural Network Model Based on Multi-Order Descartes Expansion},
  author={Li, Haifeng and Xu, Cong and Ma, Lin and Bo, Hongjian and Zhang, David},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2021},
  publisher={IEEE}
}
```

